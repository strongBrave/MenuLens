"""æ··åˆ RAG Pipeline - Search-Verify-Generate"""

import asyncio
import logging
import aiohttp
import time
from typing import List, Optional

from schemas import Dish
from config import settings
from .image_verifier import image_verifier
from .image_generator import image_generator

logger = logging.getLogger(__name__)


class HybridImagePipeline:
    """
    Search-Verify-Generate æ··åˆ Pipeline
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. æœç´¢ï¼šè·å– Top 3 ç»“æœï¼ˆè€Œéä»… Top 1ï¼‰
    2. éªŒè¯ï¼šé€šè¿‡è§†è§‰æ¨¡å‹éªŒè¯ç›¸å…³æ€§ï¼ˆScore > 0.7ï¼‰
    3. ç”Ÿæˆï¼šéªŒè¯å¤±è´¥åˆ™è°ƒç”¨å›¾ç‰‡ç”Ÿæˆæ¨¡å‹
    """
    
    def __init__(self, searcher, search_service):
        """
        åˆå§‹åŒ– Pipeline
        
        Args:
            searcher: GoogleSearcher å®ä¾‹ï¼ˆå·²é…ç½®çš„æœç´¢æœåŠ¡ï¼‰
            search_service: å®Œæ•´çš„æœç´¢æœåŠ¡ï¼ˆåŒ…å«å¤šç»“æœè·å–ï¼‰
        """
        self.searcher = searcher
        self.search_service = search_service
        self.verifier = image_verifier
        self.generator = image_generator
    
    async def get_best_image(self, dish: Dish) -> Optional[str]:
        """
        è·å–èœå“çš„æœ€ä½³å›¾ç‰‡
        
        æ‰§è¡Œæµç¨‹ï¼š
        1. æœç´¢ Top 3 å›¾ç‰‡
        2. æ£€æŸ¥ URL æœ‰æ•ˆæ€§
        3. è§†è§‰éªŒè¯ï¼ˆGatingï¼‰
        4. éªŒè¯å¤±è´¥ â†’ é™çº§ä¸ºç”Ÿæˆ
        
        Args:
            dish: èœå“å¯¹è±¡
            
        Returns:
            å›¾ç‰‡ URLï¼ˆæœç´¢æˆ–ç”Ÿæˆï¼‰
        """
        if not settings.ENABLE_RAG_PIPELINE:
            logger.info(f"RAG Pipeline disabled, using legacy search for {dish.english_name}")
            return None
        
        start_time = time.time()
        logger.info(f"ğŸ” Pipeline START for {dish.english_name}")
        
        # Step 1: æœç´¢å¤šä¸ªå€™é€‰å›¾ç‰‡
        search_start = time.time()
        candidate_urls = await self._search_candidates(dish)
        search_time = time.time() - search_start
        
        if not candidate_urls:
            logger.warning(f"âš ï¸  No search results for {dish.english_name} ({search_time:.1f}s), skipping to generation")
            return await self._generate_image(dish)
        
        logger.info(f"ğŸ“‹ Found {len(candidate_urls)} candidates ({search_time:.1f}s)")
        
        # Step 2: éªŒè¯å€™é€‰å›¾ç‰‡
        verify_start = time.time()
        best_image_url = await self._verify_and_select(dish, candidate_urls)
        verify_time = time.time() - verify_start
        
        if best_image_url:
            total_time = time.time() - start_time
            logger.info(f"âœ… Using search result ({verify_time:.1f}s verification, {total_time:.1f}s total)")
            return best_image_url
        
        # Step 3: éªŒè¯å¤±è´¥ï¼Œé™çº§ä¸ºç”Ÿæˆ
        logger.warning(f"âš ï¸  No valid search result (Score < {settings.IMAGE_VERIFY_SCORE_THRESHOLD}), "
                      f"generating image ({verify_time:.1f}s verification)")
        return await self._generate_image(dish)
    
    async def _search_candidates(self, dish: Dish) -> List[str]:
        """æœç´¢å‰ N ä¸ªå€™é€‰å›¾ç‰‡"""
        try:
            # ä½¿ç”¨æœç´¢æœåŠ¡è·å–å¤šä¸ªç»“æœ
            urls = await self.search_service.search_images(
                dish.search_term,
                num=settings.SEARCH_CANDIDATE_RESULTS
            )
            
            if not urls:
                return []
            
            # å¿«é€Ÿæ£€æŸ¥ URL æœ‰æ•ˆæ€§ï¼ˆå‘é€ HEAD è¯·æ±‚ï¼‰
            valid_urls = await self._check_urls_alive(urls)
            logger.info(f"URL validity check: {len(valid_urls)}/{len(urls)} alive")
            
            return valid_urls
            
        except Exception as e:
            logger.error(f"Error searching candidates for {dish.english_name}: {str(e)}")
            return []
    
    async def _check_urls_alive(self, urls: List[str], timeout: int = None) -> List[str]:
        """
        æ‰¹é‡æ£€æŸ¥ URL æ˜¯å¦å­˜æ´»ä¸”æ˜¯çœŸæ­£çš„å›¾ç‰‡
        
        éªŒè¯é¡¹ï¼š
        1. HTTP çŠ¶æ€ç  < 400
        2. Content-Type å¿…é¡»æ˜¯å›¾ç‰‡ç±»å‹ï¼ˆimage/jpeg, image/png, image/webpï¼‰
        3. æ’é™¤ HTML é‡å®šå‘/é”™è¯¯é¡µé¢
        """
        if timeout is None:
            timeout = settings.IMAGE_URL_CHECK_TIMEOUT
        
        VALID_IMAGE_TYPES = {
            'image/jpeg', 'image/jpg', 'image/png', 'image/webp', 'image/gif'
        }
        
        async def check_single_url(url: str) -> Optional[str]:
            try:
                timeout_obj = aiohttp.ClientTimeout(total=timeout)
                async with aiohttp.ClientSession() as session:
                    async with session.head(url, timeout=timeout_obj, allow_redirects=True) as resp:
                        if resp.status >= 400:
                            logger.debug(f"URL check failed ({resp.status}): {url[:50]}...")
                            return None
                        
                        # æ£€æŸ¥ Content-Type æ˜¯å¦æ˜¯å›¾ç‰‡
                        content_type = resp.headers.get('content-type', '').lower()
                        # æå–ä¸»ç±»å‹ï¼ˆå¤„ç† "image/jpeg; charset=utf-8" çš„æƒ…å†µï¼‰
                        base_type = content_type.split(';')[0].strip()
                        
                        if base_type not in VALID_IMAGE_TYPES:
                            logger.debug(f"Invalid content-type ({base_type}): {url[:50]}...")
                            return None
                        
                        return url
                        
            except asyncio.TimeoutError:
                logger.debug(f"URL check timeout: {url[:50]}...")
                return None
            except Exception as e:
                logger.debug(f"URL check error: {type(e).__name__}")
                return None
        
        # å¹¶å‘æ£€æŸ¥æ‰€æœ‰ URL
        tasks = [check_single_url(url) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è¿‡æ»¤æœ‰æ•ˆçš„ URL
        valid_urls = [url for url in results if isinstance(url, str)]
        return valid_urls
    
    async def _verify_and_select(
        self,
        dish: Dish,
        candidate_urls: List[str]
    ) -> Optional[str]:
        """
        è§†è§‰éªŒè¯å¹¶é€‰æ‹©æœ€ä½³å›¾ç‰‡
        
        è¿™æ˜¯ RAG Pipeline çš„æ ¸å¿ƒï¼šä½¿ç”¨ Gating Agent éªŒè¯ç›¸å…³æ€§
        """
        if not candidate_urls:
            logger.debug(f"No candidate URLs for {dish.english_name}")
            return None
        
        # å¿«é€Ÿè¿‡æ»¤ï¼šå¦‚æœåªæœ‰ 1 ä¸ªå€™é€‰ä¸”éªŒè¯å¤±è´¥ä¼šå¾ˆæµªè´¹æ—¶é—´
        # å¦‚æœå€™é€‰æ•°é‡å¾ˆå°‘ï¼Œä½¿ç”¨æ›´ä¸¥æ ¼çš„æ ‡å‡†
        if len(candidate_urls) < 2:
            logger.info(f"âš ï¸  Only {len(candidate_urls)} candidate, skipping verification (too risky)")
            return None
        
        logger.info(f"ğŸ” Verifying {len(candidate_urls)} images...")
        
        # å¹¶å‘éªŒè¯æ‰€æœ‰å€™é€‰å›¾ç‰‡
        verification_tasks = [
            self.verifier.verify_image_relevance(
                dish_name=dish.english_name,
                description=dish.description,
                image_url=url,
                original_name=dish.original_name
            )
            for url in candidate_urls
        ]
        
        scores = await asyncio.gather(*verification_tasks, return_exceptions=True)
        
        # é…å¯¹ URL å’Œåˆ†æ•°
        url_scores = []
        for url, score in zip(candidate_urls, scores):
            if isinstance(score, float):
                url_scores.append((url, score))
                logger.debug(f"  {dish.english_name}: {score:.2f} - {url[:50]}...")
        
        if not url_scores:
            return None
        
        # é€‰æ‹©æœ€é«˜åˆ†çš„å›¾ç‰‡
        best_url, best_score = max(url_scores, key=lambda x: x[1])
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        if best_score >= settings.IMAGE_VERIFY_SCORE_THRESHOLD:
            logger.info(f"âœ“ Best match: {best_score:.2f} >= {settings.IMAGE_VERIFY_SCORE_THRESHOLD}")
            return best_url
        else:
            logger.warning(f"âœ— Best score {best_score:.2f} < threshold {settings.IMAGE_VERIFY_SCORE_THRESHOLD}")
            return None
    
    async def _generate_image(self, dish: Dish) -> Optional[str]:
        """é™çº§ï¼šç”Ÿæˆå›¾ç‰‡"""
        if not settings.ENABLE_IMAGE_GENERATION:
            logger.warning(f"Image generation disabled, returning None for {dish.english_name}")
            return None
        
        logger.info(f"ğŸ¨ Generating image for {dish.english_name}...")
        
        try:
            image_url = await self.generator.generate_image(
                english_name=dish.english_name,
                original_name=dish.original_name,
                description=dish.description
            )
            
            if image_url:
                logger.info(f"âœ¨ Generated image URL: {image_url[:60]}...")
            
            return image_url
            
        except Exception as e:
            logger.error(f"Error generating image: {str(e)}")
            return None
    
    async def enrich_dishes_with_images(self, dishes: List[Dish]) -> List[Dish]:
        """
        ä¸ºèœå“åˆ—è¡¨å¹¶å‘è·å–æœ€ä½³å›¾ç‰‡ï¼ˆä½¿ç”¨æ··åˆ Pipelineï¼‰
        
        Args:
            dishes: èœå“åˆ—è¡¨
            
        Returns:
            å¸¦æœ‰å›¾ç‰‡çš„èœå“åˆ—è¡¨
        """
        logger.info(f"ğŸš€ Hybrid Pipeline processing {len(dishes)} dishes...")
        
        # å¹¶å‘å¤„ç†æ‰€æœ‰èœå“
        tasks = [self.get_best_image(dish) for dish in dishes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ›´æ–°èœå“å›¾ç‰‡
        success_count = 0
        for dish, image_url in zip(dishes, results):
            if isinstance(image_url, str) and image_url:
                dish.image_url = image_url
                success_count += 1
            elif isinstance(image_url, Exception):
                logger.warning(f"Exception for {dish.english_name}: {image_url}")
        
        logger.info(f"âœ… Pipeline completed: {success_count}/{len(dishes)} dishes got images")
        return dishes


# å…¨å±€å®ä¾‹ï¼ˆåœ¨ main.py ä¸­åˆå§‹åŒ–ï¼‰
hybrid_pipeline = None


def initialize_hybrid_pipeline(searcher, search_service):
    """åˆå§‹åŒ–å…¨å±€ Pipeline å®ä¾‹"""
    global hybrid_pipeline
    hybrid_pipeline = HybridImagePipeline(searcher, search_service)
    logger.info("âœ… Hybrid Pipeline initialized")
    return hybrid_pipeline
